{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-25T08:17:10.363996Z",
     "start_time": "2024-12-25T08:17:10.351224Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "from tqdm.auto import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:17:10.414325Z",
     "start_time": "2024-12-25T08:17:10.375852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the seed for reproducibility\n",
    "#seed = 42\n",
    "#random.seed(seed)\n",
    "#torch.manual_seed(seed)\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.mps.is_available():\n",
    "    # ı am using mps for test this project\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# data dircetory\n",
    "data_dir = \"dataset/\"\n",
    "\n",
    "# Globel variables\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n"
   ],
   "id": "51abe5f3ee5e280e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:17:11.269611Z",
     "start_time": "2024-12-25T08:17:11.266045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "class RemoveTopPixels:\n",
    "    def __init__(self, pixels_to_remove):\n",
    "        self.pixels_to_remove = pixels_to_remove\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Görüntünün boyutlarını al\n",
    "        width, height = img.size\n",
    "        # Üst 200 pikseli kırp\n",
    "        cropped_img = img.crop((0, self.pixels_to_remove, width, height))\n",
    "        return cropped_img"
   ],
   "id": "7508bc470236bd",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:17:12.025980Z",
     "start_time": "2024-12-25T08:17:11.465254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    #RemoveTopPixels(200),\n",
    "    transforms.Resize((100, 280)),\n",
    "    #transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "# Split the dataset into train, validation, and test sets\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.33, stratify=dataset.targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ],
   "id": "861ba662d787acc8",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:46.307116Z",
     "start_time": "2024-12-25T08:17:12.432609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT).to(device)\n",
    "#model = models.mobilenet_v3_large(pretrained=True).to(device)\n",
    "#model = TinyVGG(input_shape=3, hidden_units=64, output_shape=3).to(device)\n",
    "#model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "\"\"\"model = SimpleViT(\n",
    "    image_size = 256,\n",
    "    patch_size = BATCH_SIZE,\n",
    "    num_classes = 1000,\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 1024\n",
    ").to(device)\"\"\"\n",
    "\n",
    "# Print model summary\n",
    "#torchinfo.summary(model, input_size=(8, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 10  # Set to 10 for testing, adjust as needed\n",
    "\n",
    "total_accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, targets in tqdm(train_loader, desc=\"Training Progress\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)  # Average training loss\n",
    "    test_loss /= len(test_loader)  # Average test loss\n",
    "    accuracy = 100 * correct / total  # Test accuracy\n",
    "    total_accuracy += accuracy\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "#print(f\"Average accuracy efficientnet_v2_s: {total_accuracy / num_epochs:.2f}%\")\n"
   ],
   "id": "575c9ea49a378e9f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:26<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 7.1284, Test Loss: 6.2666, Accuracy: 1.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 5.5796, Test Loss: 4.8496, Accuracy: 24.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 3.7713, Test Loss: 3.6147, Accuracy: 45.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 1.9009, Test Loss: 2.7160, Accuracy: 58.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:06<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 1.0686, Test Loss: 1.8758, Accuracy: 67.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 0.4485, Test Loss: 1.5198, Accuracy: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:11<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 0.1637, Test Loss: 1.4765, Accuracy: 68.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 0.1088, Test Loss: 1.5198, Accuracy: 72.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 0.0543, Test Loss: 1.4611, Accuracy: 77.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Training Loss: 0.0600, Test Loss: 1.4672, Accuracy: 77.14%\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:48.536760Z",
     "start_time": "2024-12-25T08:18:47.172705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Ml part with SVC\")\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-2])\n",
    "model.eval()\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_Test = []\n",
    "y_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        features = feature_extractor(inputs)\n",
    "        features = features.view(features.size(0), -1)  # Flattening\n",
    "        X_train.extend(features.cpu().numpy())\n",
    "        y_train.extend(labels.cpu().numpy())\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        features = feature_extractor(inputs)\n",
    "        features = features.view(features.size(0), -1)  # Flattening\n",
    "        X_Test.extend(features.cpu().numpy())\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_Test = np.array(X_Test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_Test_scaled = scaler.transform(X_Test)\n",
    "\n",
    "del X_train, X_Test"
   ],
   "id": "a837581ee83652a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ml part with SVC\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:49.193910Z",
     "start_time": "2024-12-25T08:18:48.801136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = SVC(kernel=\"rbf\", C=1, gamma=\"scale\")\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_Test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n"
   ],
   "id": "f39bd62646271384",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7285714285714285\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:50.641571Z",
     "start_time": "2024-12-25T08:18:49.376304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_Test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ],
   "id": "8cc8370da1845e49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7857142857142857\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:50.981214Z",
     "start_time": "2024-12-25T08:18:50.648912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_Test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ],
   "id": "b69f38e8330d8ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7571428571428571\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T08:18:52.066155Z",
     "start_time": "2024-12-25T08:18:51.369302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_Test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ],
   "id": "db10436739b86ace",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7142857142857143\n"
     ]
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
